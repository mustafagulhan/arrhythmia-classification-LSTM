{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFhi7QVJIMYQ",
        "outputId": "5c863347-2750-455b-9138-61617fe7352a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m141.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. ADIM: KURULUM VE DRİVE BAĞLANTISI\n",
        "# ==========================================\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Drive Bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Gerekli kütüphaneyi kur (MIT-BIH okumak için)\n",
        "!pip install -q wfdb\n",
        "\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. ADIM: VERİ İNDİRME (Senin düzenin)\n",
        "# ==========================================\n",
        "# Veriyi senin klasörüne indiriyoruz (zaten varsa indirmez)\n",
        "data_dir = \"/content/drive/MyDrive/mitdb\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Veri setini kontrol et, yoksa indir\n",
        "if len(os.listdir(data_dir)) < 10:\n",
        "    print(\"MIT-BIH veriseti indiriliyor...\")\n",
        "    !wget -q -r -N -c -np https://physionet.org/files/mitdb/1.0.0/ -P /content/\n",
        "    !cp -r /content/physionet.org/files/mitdb/1.0.0/* \"{data_dir}/\"\n",
        "    print(\"İndirme tamamlandı.\")\n",
        "else:\n",
        "    print(\"MIT-BIH veriseti zaten Drive'da mevcut.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUa9qT5NRXFi",
        "outputId": "2be9af19-d09d-4ded-f5a9-70334d9bb0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MIT-BIH veriseti zaten Drive'da mevcut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. ADIM: RR ARALIKLARINI ÇIKARMA (ÖNEMLİ KISIM)\n",
        "# ==========================================\n",
        "# Hangi sembollerin \"Normal\", hangilerinin \"Aritmi\" olduğunu tanımlıyoruz\n",
        "# N: Normal, L: Left bundle branch block, R: Right... (Bunları Normal sayabiliriz veya ayırabiliriz)\n",
        "# Basitlik için: Normal dışı her şeye \"1\" (Aritmi) diyeceğiz.\n",
        "\n",
        "NORMAL_SYMBOLS = ['N', 'L', 'R', 'e', 'j']\n",
        "# Diğer tüm semboller Aritmi (A, V, F, / ...) kabul edilecek\n",
        "\n",
        "def load_data_from_mitbih(records, seq_len=10):\n",
        "    X_all = []\n",
        "    y_all = []\n",
        "\n",
        "    print(\"Veriler işleniyor (RR Aralıkları hesaplanıyor)...\")\n",
        "\n",
        "    for record in records:\n",
        "        try:\n",
        "            # Sadece anotasyon dosyasını (ATR) okumak yeterli, sinyale gerek yok!\n",
        "            # Çünkü bize sadece \"vuruş zamanları\" lazım.\n",
        "            ann = wfdb.rdann(f\"{data_dir}/{record}\", 'atr')\n",
        "\n",
        "            # RR Aralıklarını Hesapla (Sample farkı / 360Hz)\n",
        "            # np.diff: Bir sonraki vuruştan öncekini çıkarır\n",
        "            rr_intervals = np.diff(ann.sample) / 360.0\n",
        "\n",
        "            # Sembolleri al (İlk vuruşun RR'ı olmadığı için sembollerde 1. indexten başlarız)\n",
        "            symbols = np.array(ann.symbol[1:])\n",
        "\n",
        "            # RR ve Sembol uzunluğunu eşitle\n",
        "            min_len = min(len(rr_intervals), len(symbols))\n",
        "            rr_intervals = rr_intervals[:min_len]\n",
        "            symbols = symbols[:min_len]\n",
        "\n",
        "            # --- VALIDASYON ---\n",
        "            # Çok uzun (örn > 2sn) veya çok kısa (örn < 0.2sn) hatalı ölçümleri atabiliriz\n",
        "            valid_indices = (rr_intervals > 0.2) & (rr_intervals < 2.0)\n",
        "            rr_intervals = rr_intervals[valid_indices]\n",
        "            symbols = symbols[valid_indices]\n",
        "\n",
        "            # --- SEQUENCE OLUŞTURMA (LSTM İÇİN) ---\n",
        "            # Son 10 vuruşa bakıp, sıradaki vuruşun ne olduğunu tahmin edeceğiz (veya o dizinin durumunu)\n",
        "            for i in range(len(rr_intervals) - seq_len):\n",
        "                sequence = rr_intervals[i : i+seq_len]\n",
        "                target_symbol = symbols[i+seq_len] # Sequence sonundaki vuruş\n",
        "\n",
        "                # Etiketleme: Normal mi Aritmi mi?\n",
        "                label = 0 if target_symbol in NORMAL_SYMBOLS else 1\n",
        "\n",
        "                # Sadece 'bilinen' beat tiplerini al (Gürültü vs. atla)\n",
        "                if target_symbol in NORMAL_SYMBOLS or target_symbol in ['A', 'a', 'J', 'S', 'V', 'E', 'F']:\n",
        "                    X_all.append(sequence)\n",
        "                    y_all.append(label)\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    return np.array(X_all), np.array(y_all)\n",
        "\n",
        "# Kayıt Listesi (100 ile 234 arasındaki dosyalar)\n",
        "all_records = [f.replace('.dat','') for f in os.listdir(data_dir) if f.endswith('.dat')]\n",
        "# Hepsini kullanmak uzun sürebilir, demo için ilk 10-20 tanesini alalım\n",
        "# Hepsini istersen: selected_records = all_records\n",
        "selected_records = all_records[:20]\n",
        "\n",
        "X, y = load_data_from_mitbih(selected_records, seq_len=10)\n",
        "\n",
        "print(f\"\\nToplam Örnek Sayısı: {len(X)}\")\n",
        "print(f\"Normal Sayısı: {sum(y==0)}\")\n",
        "print(f\"Aritmi Sayısı: {sum(y==1)}\")\n",
        "\n",
        "# --- DENGESİZ VERİ SETİ DÜZELTME (Opsiyonel ama Önerilir) ---\n",
        "# Normal veri çok fazladır, Aritmi azdır. Eşitleyelim.\n",
        "X_normal = X[y==0]\n",
        "X_arrhythmia = X[y==1]\n",
        "\n",
        "# Normalleri azalt (Undersampling)\n",
        "X_normal_down = resample(X_normal, replace=False, n_samples=len(X_arrhythmia), random_state=42)\n",
        "\n",
        "X_balanced = np.concatenate([X_normal_down, X_arrhythmia])\n",
        "y_balanced = np.concatenate([np.zeros(len(X_arrhythmia)), np.ones(len(X_arrhythmia))])\n",
        "\n",
        "print(f\"Dengelenmiş Veri Seti: {len(X_balanced)} örnek\")\n",
        "\n",
        "# Eğitim/Test Ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# LSTM Formatına Sokma: [Örnek, Zaman, Özellik]\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F79oQsN-RZpq",
        "outputId": "47f86e71-bc3c-4e1a-c8a3-6247534dbb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veriler işleniyor (RR Aralıkları hesaplanıyor)...\n",
            "\n",
            "Toplam Örnek Sayısı: 35599\n",
            "Normal Sayısı: 34139\n",
            "Aritmi Sayısı: 1460\n",
            "Dengelenmiş Veri Seti: 2920 örnek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. ADIM: LSTM MODEL EĞİTİMİ\n",
        "# ==========================================\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(10, 1))) # 10 adım geriye bakıyoruz\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid')) # 0 veya 1\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nModel Eğitiliyor...\")\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbHfrdiXRcla",
        "outputId": "e4763bc6-1a5a-4497-eb0a-319dfff4ee8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Eğitiliyor...\n",
            "Epoch 1/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5060 - loss: 0.6942 - val_accuracy: 0.4983 - val_loss: 0.6923\n",
            "Epoch 2/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5241 - loss: 0.6924 - val_accuracy: 0.5325 - val_loss: 0.6910\n",
            "Epoch 3/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5093 - loss: 0.6912 - val_accuracy: 0.5017 - val_loss: 0.6930\n",
            "Epoch 4/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5091 - loss: 0.6919 - val_accuracy: 0.5342 - val_loss: 0.6861\n",
            "Epoch 5/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5413 - loss: 0.6849 - val_accuracy: 0.5034 - val_loss: 0.6903\n",
            "Epoch 6/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5439 - loss: 0.6867 - val_accuracy: 0.5394 - val_loss: 0.6761\n",
            "Epoch 7/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 0.6759 - val_accuracy: 0.5565 - val_loss: 0.6743\n",
            "Epoch 8/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5661 - loss: 0.6722 - val_accuracy: 0.5822 - val_loss: 0.6666\n",
            "Epoch 9/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5935 - loss: 0.6546 - val_accuracy: 0.5942 - val_loss: 0.6535\n",
            "Epoch 10/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5819 - loss: 0.6580 - val_accuracy: 0.5342 - val_loss: 0.6663\n",
            "Epoch 11/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6169 - loss: 0.6353 - val_accuracy: 0.6233 - val_loss: 0.6199\n",
            "Epoch 12/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6543 - loss: 0.6034 - val_accuracy: 0.6764 - val_loss: 0.5524\n",
            "Epoch 13/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6895 - loss: 0.5515 - val_accuracy: 0.6849 - val_loss: 0.5672\n",
            "Epoch 14/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7323 - loss: 0.5244 - val_accuracy: 0.7586 - val_loss: 0.5166\n",
            "Epoch 15/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7658 - loss: 0.4832 - val_accuracy: 0.7397 - val_loss: 0.5293\n",
            "Epoch 16/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7612 - loss: 0.4956 - val_accuracy: 0.7637 - val_loss: 0.5039\n",
            "Epoch 17/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7750 - loss: 0.4769 - val_accuracy: 0.7603 - val_loss: 0.5110\n",
            "Epoch 18/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7828 - loss: 0.4752 - val_accuracy: 0.7586 - val_loss: 0.5102\n",
            "Epoch 19/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7807 - loss: 0.4849 - val_accuracy: 0.7723 - val_loss: 0.4962\n",
            "Epoch 20/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7847 - loss: 0.4742 - val_accuracy: 0.7774 - val_loss: 0.4964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. ADIM: MODELİ KAYDETME\n",
        "# ==========================================\n",
        "save_path = '/content/drive/MyDrive/mitdb/lstm_arrhythmia_model.h5'\n",
        "model.save(save_path)\n",
        "print(f\"\\n✅ Model kaydedildi: {save_path}\")\n",
        "print(\"Bu dosyayı indirip Raspberry Pi'ye atabilirsin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EExQ_GOeRel5",
        "outputId": "b6ef4431-44ee-484c-9bb0-864bfeaec33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model kaydedildi: /content/drive/MyDrive/mitdb/lstm_arrhythmia_model.h5\n",
            "Bu dosyayı indirip Raspberry Pi'ye atabilirsin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00bcc181",
        "outputId": "5a990995-bffa-4374-aec8-3c7c58bbd474"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "save_path = '/content/drive/MyDrive/mitdb/lstm_arrhythmia_model.h5'\n",
        "model = load_model(save_path)\n",
        "print(f\"Model başarıyla yüklendi: {save_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model başarıyla yüklendi: /content/drive/MyDrive/mitdb/lstm_arrhythmia_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4778e9a0",
        "outputId": "828edd60-6027-4d0e-f77e-dd1275cc25a9"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Test seti üzerinde tahminler yap\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int) # Eşik değeri 0.5 ile ikili tahminlere çevir\n",
        "\n",
        "# Sınıflandırma raporunu yazdır\n",
        "print(\"\\nModel Performans Raporu:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Normal', 'Aritmi']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\n",
            "Model Performans Raporu:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.71      0.92      0.81       291\n",
            "      Aritmi       0.89      0.63      0.74       293\n",
            "\n",
            "    accuracy                           0.78       584\n",
            "   macro avg       0.80      0.78      0.77       584\n",
            "weighted avg       0.80      0.78      0.77       584\n",
            "\n"
          ]
        }
      ]
    }
  ]
}